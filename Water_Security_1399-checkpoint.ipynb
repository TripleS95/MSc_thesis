{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read main data\n",
    "data=pd.read_excel(r'D:\\Personal\\University\\Master\\Thesis\\Water Security in 1399\\data_values_1399.xlsx',sheet_name='data_transpose')\n",
    "rainfall_data=pd.read_excel(r'D:\\Personal\\University\\Master\\Thesis\\Aggregation-Weighting\\rainfall_data.xlsx',sheet_name='Sheet1')\n",
    "\n",
    "# Read data necessary for normalization\n",
    "ind_type=pd.read_excel(r'D:\\Personal\\University\\Master\\Thesis\\Water Security in 1399\\indicator_type_1399.xlsx',sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining normalization function for (dam capicity)/(surface rwr)\n",
    "def damcap_normalize(ser1,ser2):\n",
    "    result=ser1*0\n",
    "    length=ser1.size\n",
    "    for i in range(length):\n",
    "        if ser1[i]>=ser2[i]:\n",
    "            result[i]=(ser1.max()-ser1[i])/(ser1.max()-ser2[i])\n",
    "        else:\n",
    "            result[i]=(ser1[i]-ser1.min())/(ser2[i]-ser1.min())\n",
    "        if result[i]<0.01:\n",
    "            result[i]=0.01\n",
    "    return result  \n",
    "\n",
    "#defining aggregation functions\n",
    "def aggregate(df,a=0.5):\n",
    "    size=len(df.columns)\n",
    "    result=(df.product(axis=1)**(1/size))*a+df.mean(axis=1)*(1-a)\n",
    "    return result\n",
    "\n",
    "#defining weighted aggregation functions\n",
    "def weighted_addminagg(dfi,dfw,a=0.5):\n",
    "    weight_array=np.array(dfw)[0]\n",
    "    dfmin=dfi.min(axis=1)\n",
    "    weighted_sum=dfi.multiply(weight_array,axis='columns').sum(axis=1)\n",
    "    result=a*dfmin+(1-a)*weighted_sum\n",
    "    return result\n",
    "\n",
    "def weighted_sum(dfi,dfw):\n",
    "    weight_array=np.array(dfw)[0]\n",
    "    weighted_sum=dfi.multiply(weight_array,axis='columns').sum(axis=1)\n",
    "    return weighted_sum\n",
    "\n",
    "def geomean(dfi):\n",
    "    size=len(dfi.columns)\n",
    "    weighted_geomean=dfi.pow(weight_array,axis='columns').product(axis='columns')\n",
    "    return weighted_geomean\n",
    "\n",
    "def weighted_geomean(dfi,dfw):\n",
    "    weight_array=np.array(dfw)[0]\n",
    "    weighted_geomean=dfi.pow(weight_array,axis='columns').product(axis='columns')\n",
    "    return weighted_geomean\n",
    "\n",
    "def weighted_addgeo(dfi,dfw,a=0.5):\n",
    "    weight_array=np.array(dfw)[0]\n",
    "    weighted_geomean=dfi.pow(weight_array,axis='columns').product(axis='columns')\n",
    "    weighted_sum=dfi.multiply(weight_array,axis='columns').sum(axis=1)\n",
    "    result= a*weighted_geomean+(1-a)*weighted_sum\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting rainfall data after 1366 (nearly 30 years)\n",
    "rainfall_modified=rainfall_data.loc[(rainfall_data['syear']>1366) & (rainfall_data['syear']<1399)]\n",
    "\n",
    "#making a dictionary of provinces and their respective data\n",
    "pr=list(rainfall_modified.ostan.unique())\n",
    "prdict={elem:pd.DataFrame() for elem in pr}\n",
    "for key in prdict.keys():\n",
    "    prdict[key]=rainfall_modified[:][rainfall_modified.ostan==key]\n",
    "    \n",
    "#making a dictionary consisting of province names as keys and annual precipitation as respective values\n",
    "annualrain_dict={x:pd.DataFrame() for x in pr}\n",
    "for key in annualrain_dict.keys():\n",
    "    annualrain_dict[key]=prdict[key].groupby('syear').precnew.sum()\n",
    "\n",
    "#calculating coefficients of variation\n",
    "interannual_varicoef={x:pd.DataFrame() for x in pr}\n",
    "for key in interannual_varicoef.keys():\n",
    "    interannual_varicoef[key]=annualrain_dict[key].std()/annualrain_dict[key].mean()\n",
    "monthly_varicoef={x:pd.DataFrame() for x in pr}\n",
    "for key in monthly_varicoef.keys():\n",
    "    monthly_varicoef[key]=prdict[key].precnew.std()/prdict[key].precnew.mean()\n",
    "annualevap_varicoef={x:pd.DataFrame() for x in pr}\n",
    "\n",
    "#converting monthly coefficient of variation to dataframe and sorting it based on original data\n",
    "monthlyvaricoeff_df = pd.DataFrame(monthly_varicoef.items(),columns=['province', 'monthly_varicoeff'])\n",
    "monthlyvaricoeff_df = monthlyvaricoeff_df.drop([31])\n",
    "monthlyvaricoeff_df = monthlyvaricoeff_df.set_index('province')\n",
    "monthlyvaricoeff_df = monthlyvaricoeff_df.reindex(index=data['province'])\n",
    "monthlyvaricoeff_df = monthlyvaricoeff_df.reset_index()\n",
    "\n",
    "#converting annual coefficient of variation to dataframe and sorting it based on original data\n",
    "intanvaricoeff_df = pd.DataFrame(interannual_varicoef.items(),columns=['province', 'rain_coeff_variability'])\n",
    "intanvaricoeff_df = intanvaricoeff_df.drop([31])\n",
    "intanvaricoeff_df = intanvaricoeff_df.set_index('province')\n",
    "intanvaricoeff_df = intanvaricoeff_df.reindex(index=data['province'])\n",
    "intanvaricoeff_df = intanvaricoeff_df.reset_index()\n",
    "\n",
    "# adding calculated coefficients of variation to the data\n",
    "data['rain_coeff_variation']=intanvaricoeff_df['rain_coeff_variability']\n",
    "data['monthly_varicoeff']= monthlyvaricoeff_df['monthly_varicoeff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dataframe consisting of necessary variables for the calculation of sub-indicators\n",
    "variables=pd.DataFrame()\n",
    "variables['province']=data.province\n",
    "variables['irwr']=data.precipitation-data.evaporation\n",
    "variables['surf_irwr']=(data.precipitation-data.evaporation)*data.runoff_coeff\n",
    "variables['withdraw_surf']=data.iloc[:,5:8].sum(axis=1)\n",
    "variables['gw_irwr']=(data.precipitation-data.evaporation)*(1-data.runoff_coeff)\n",
    "variables['withdraw_gw']=data.iloc[:,8:11].sum(axis=1)\n",
    "variables['withdraw_agr']=data.withdraw_gw_agr+data.withdraw_surf_agr\n",
    "variables['withdraw_ind']=data.withdraw_gw_ind+data.withdraw_surf_ind\n",
    "variables['access_sanitation_total']=(data.access_sanitation_urban*data.urban_pop_ratio+data.access_sanitation_rural*(1-data.urban_pop_ratio))\n",
    "variables['deficit_gw_annual']=data.annual_gw_variation*(-1)\n",
    "variables['deficit_gw_aggregate']=data.aggregate_gw_variation*(-1)\n",
    "variables['withdraw_total']=np.NaN\n",
    "variables['withdraw_total']=data[['withdraw_surf_agr','withdraw_surf_ind','withdraw_surf_dom','withdraw_gw_agr','withdraw_gw_ind','withdraw_gw_dom']].sum(axis=1)\n",
    "variables['agr_withdraw_ratio']=variables['withdraw_agr']/variables['withdraw_total']\n",
    "variables['access_sanitation_total']=data['access_sanitation_urban']*data['urban_pop_ratio']+data['access_sanitation_rural']*(1-data['urban_pop_ratio'])\n",
    "\n",
    "#setting negative deficit values equal to zero\n",
    "variables.loc[variables['deficit_gw_annual'] < 0 ,'deficit_gw_annual']=0\n",
    "variables.loc[variables['deficit_gw_aggregate'] < 0 ,'deficit_gw_aggregate']=0\n",
    "variables['withdraw_gw_allowable']=variables.gw_irwr-(variables.deficit_gw_aggregate/17)\n",
    "variables['withdraw_agr_decrease']=variables.withdraw_gw-variables.withdraw_gw_allowable\n",
    "variables.loc[variables['withdraw_agr_decrease']<0,'withdraw_agr_decrease']=0\n",
    "variables['agrwat_lost_ratio']=variables.withdraw_agr_decrease/variables.withdraw_agr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dataframe for the sub-indicators\n",
    "#Dimension 1: Resources\n",
    "sub_indicators=pd.DataFrame()\n",
    "sub_indicators['rain_coeff_variation']=data['rain_coeff_variation']\n",
    "sub_indicators['monthly_varicoeff']=data['monthly_varicoeff']\n",
    "sub_indicators['gw_agdef_gwrwr']=(variables.deficit_gw_aggregate/variables.gw_irwr).abs()\n",
    "sub_indicators['gw_andef_withdraw']=variables.deficit_gw_annual/variables.withdraw_gw\n",
    "sub_indicators['agr_dependency_gw']=data.withdraw_gw_agr/variables.withdraw_agr\n",
    "sub_indicators['ind_dependency_gw']=data.withdraw_gw_ind/variables.withdraw_ind\n",
    "sub_indicators['urbanwat_dependency_gw']=data.withdraw_urban_gw/data.produced_urban_wat\n",
    "sub_indicators['ruralwat_dependency_gw']=data.withdraw_rural_gw/data.produced_rural_wat\n",
    "sub_indicators['withdraw_surf_ratio']=variables.withdraw_surf/variables.surf_irwr\n",
    "sub_indicators['withdraw_gw_ratio']=variables.withdraw_gw/variables.gw_irwr\n",
    "sub_indicators['anomaly_rain']=abs(data['anomaly_rain'])\n",
    "sub_indicators['anomaly_temp']=data['anomaly_temp']\n",
    "sub_indicators['irwr_percap']=(variables.irwr*(10**6)/data.population)/(1+data['pop_growth']/100)\n",
    "#Dimension 2: access\n",
    "\n",
    "sub_indicators['access_wat_urban']=data['access_wat_urban']\n",
    "sub_indicators['access_wat_rural']=data['access_wat_rural']\n",
    "sub_indicators['under_stress_pop']=data['under_stress_pop']\n",
    "sub_indicators['access_sanitation_urban']=data['access_sanitation_urban']\n",
    "sub_indicators['access_sanitation_rural']=data['access_sanitation_rural']\n",
    "sub_indicators['treated_municipal_wastewater']=data.waste_facility_cap/data.daily_produced_waste\n",
    "sub_indicators['quality_proxy']=data.urban_fam_treatwat/data.total_urban_fam\n",
    "sub_indicators['damcap_rwr_ratio']=data.dam_cap/variables.surf_irwr\n",
    "\n",
    "#Dimension 3:Economy\n",
    "sub_indicators['efficiency_agr']=data.agr_added_value/variables.withdraw_agr\n",
    "sub_indicators['modern_irrig']=data.land_irrig_modern/data.land_irrig_tot\n",
    "sub_indicators['employment_lost_agr']=variables.agrwat_lost_ratio*data.agr_employment\n",
    "sub_indicators['unaccounted_wat_urban']=data['unaccounted_wat_urban']\n",
    "sub_indicators['unaccounted_wat_rural']=data['unaccounted_wat_rural']\n",
    "sub_indicators['efficiency_ind']=data.ind_added_value/variables.withdraw_ind\n",
    "\n",
    "sub_indicators.index=variables['province']\n",
    "sub_indicators.loc['khuz','damcap_rwr_ratio']=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing Data\n",
    "normalized=sub_indicators*0\n",
    "max_allowable_withdraw=variables['withdraw_gw_allowable']/variables['gw_irwr']\n",
    "max_allowable_withdraw.index=sub_indicators.index\n",
    "\n",
    "for col in ind_type.columns:\n",
    "    i=ind_type.columns.get_loc(col)\n",
    "    if ind_type.loc[2,col]=='b': # The bigger the better indicators\n",
    "        normalized.loc[sub_indicators[col]>=ind_type.loc[0,col],col]=1\n",
    "        normalized.loc[sub_indicators[col]<=ind_type.loc[1,col],col]=0.01\n",
    "        cond=(sub_indicators[col]>ind_type.loc[1,col])& (sub_indicators[col]<ind_type.loc[0,col])\n",
    "        normalized.loc[cond,col]=(sub_indicators.loc[cond,col]-ind_type.loc[1,col])/(ind_type.loc[0,col]-ind_type.loc[1,col])\n",
    "    elif ind_type.loc[2,col]=='l':      # The lower the better indicators\n",
    "        normalized.loc[sub_indicators[col]<=ind_type.loc[0,col],col]=1\n",
    "        normalized.loc[sub_indicators[col]>=ind_type.loc[1,col],col]=0.01\n",
    "        cond=(sub_indicators[col]<ind_type.loc[1,col])& (sub_indicators[col]>ind_type.loc[0,col])\n",
    "        normalized.loc[cond,col]=(ind_type.loc[1,col]-sub_indicators.loc[cond,col])/(ind_type.loc[1,col]-ind_type.loc[0,col])\n",
    "    elif ind_type.loc[2,col]=='diff':    # GW withdrawal to rwr ratio normalization\n",
    "        cond1=(sub_indicators[col] > max_allowable_withdraw)\n",
    "        normalized.loc[cond1,col]=0.01\n",
    "        cond2=sub_indicators[col]<0.25\n",
    "        normalized.loc[cond2,col]=1\n",
    "        cond3=(sub_indicators[col] < max_allowable_withdraw) & (sub_indicators[col]>0.25)\n",
    "        normalized.loc[cond3,col]=(max_allowable_withdraw.loc[cond3]-sub_indicators.loc[cond3,col])/(max_allowable_withdraw.loc[cond3]-0.25)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dam capacity to surface rwr ratio normalization    \n",
    "variation_coeff_agg=pd.Series(normalized[['rain_coeff_variation','monthly_varicoeff']].mean(axis=1),index=variables['province'])\n",
    "variation_coeff_bins=pd.cut(variation_coeff_agg,4,labels=['Q1','Q2','Q3','Q4'])\n",
    "ideal_damcap=pd.Series(index=variables['province'],dtype='float64') \n",
    "ideal_damcap[variation_coeff_bins=='Q1']=1\n",
    "ideal_damcap[variation_coeff_bins=='Q2']=0.9\n",
    "ideal_damcap[variation_coeff_bins=='Q3']=0.8\n",
    "ideal_damcap[variation_coeff_bins=='Q4']=0.7\n",
    "normalized['damcap_rwr_ratio']=damcap_normalize(sub_indicators['damcap_rwr_ratio'],ideal_damcap)   \n",
    "normalized.loc['khuz','damcap_rwr_ratio']=0.45\n",
    "\n",
    "# modifying modern irrigation indicator vlues based on aggregate GW reservoir deficits\n",
    "gw_deficit_agg=pd.Series(aggregate(normalized[['gw_agdef_gwrwr','gw_andef_withdraw']]),index=variables['province'])\n",
    "gw_deficit_bins=pd.cut(gw_deficit_agg,4,labels=['Q1','Q2','Q3','Q4'])\n",
    "gw_modifier=pd.Series(index=variables['province'],dtype='float64')\n",
    "gw_modifier[gw_deficit_bins=='Q1']=0.8\n",
    "gw_modifier[gw_deficit_bins=='Q2']=0.9\n",
    "gw_modifier[gw_deficit_bins=='Q3']=1\n",
    "gw_modifier[gw_deficit_bins=='Q4']=1\n",
    "normalized['modern_irrig']=normalized['modern_irrig'].multiply(gw_modifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Aggregation Level</th>\n",
       "      <th colspan=\"3\" halign=\"left\">WSI</th>\n",
       "      <th colspan=\"2\" halign=\"left\">R1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">R2</th>\n",
       "      <th colspan=\"3\" halign=\"left\">R3</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">A3</th>\n",
       "      <th colspan=\"3\" halign=\"left\">E1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">E2</th>\n",
       "      <th colspan=\"3\" halign=\"left\">E3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indicator</th>\n",
       "      <th>Resource</th>\n",
       "      <th>Access</th>\n",
       "      <th>Economy</th>\n",
       "      <th>ACV</th>\n",
       "      <th>MCV</th>\n",
       "      <th>Dag</th>\n",
       "      <th>Dan</th>\n",
       "      <th>GWDagr</th>\n",
       "      <th>GWDind</th>\n",
       "      <th>GWDurb</th>\n",
       "      <th>...</th>\n",
       "      <th>DC</th>\n",
       "      <th>SS</th>\n",
       "      <th>AE</th>\n",
       "      <th>MI</th>\n",
       "      <th>EL</th>\n",
       "      <th>NRWurb</th>\n",
       "      <th>NRWrur</th>\n",
       "      <th>Eagr</th>\n",
       "      <th>IE</th>\n",
       "      <th>NRW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Weight</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Aggregation Level      WSI                   R1          R2           R3  \\\n",
       "Indicator         Resource Access Economy   ACV   MCV   Dag   Dan GWDagr   \n",
       "Weight                 0.5   0.29    0.21  0.72  0.28  0.66  0.34   0.23   \n",
       "\n",
       "Aggregation Level                ...    A3          E1                 E2  \\\n",
       "Indicator         GWDind GWDurb  ...    DC    SS    AE    MI    EL NRWurb   \n",
       "Weight              0.09    0.4  ...  0.16  0.18  0.62  0.16  0.22    0.8   \n",
       "\n",
       "Aggregation Level           E3              \n",
       "Indicator         NRWrur  Eagr    IE   NRW  \n",
       "Weight               0.2  0.68  0.15  0.17  \n",
       "\n",
       "[1 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading AHP weights from csv files\n",
    "eco_weights=pd.read_csv('eco_modified_weights.csv')\n",
    "acc_weights=pd.read_csv('acc_modified_weights.csv')\n",
    "res_weights=pd.read_csv('res_modified_weights.csv')\n",
    "wsi_weights=pd.read_csv('wsi_modified_weights.csv')\n",
    "\n",
    "eco_weights.drop(columns='Unnamed: 0',inplace=True)\n",
    "arrayeco=[['E1','E1','E1','E2','E2','E3','E3','E3'],list(eco_weights.iloc[0,:])]\n",
    "eco_weights.columns=pd.MultiIndex.from_arrays(arrayeco, names=('Aggregation Level', 'Indicator'))\n",
    "eco_weights.drop(index=0,inplace=True)\n",
    "eco_weights.index=['Weight']\n",
    "eco_weights=eco_weights.astype('float')\n",
    "\n",
    "acc_weights.drop(columns='Unnamed: 0',inplace=True)\n",
    "arrayacc=[['A1','A1','A1','A2','A2','A2','A3','A3','A3','A3'],list(acc_weights.iloc[0,:])]\n",
    "acc_weights.columns=pd.MultiIndex.from_arrays(arrayacc, names=('Aggregation Level', 'Indicator'))\n",
    "acc_weights.drop(index=0,inplace=True)\n",
    "acc_weights.index=['Weight']\n",
    "acc_weights=acc_weights.astype('float')\n",
    "\n",
    "res_weights.drop(columns='Unnamed: 0',inplace=True)\n",
    "arrayres=[['R1','R1','R2','R2','R3','R3','R3','R3','R4','R4','R5','R5','R5','R6','R6','R7','R7','R7','R7'],list(res_weights.iloc[0,:])]\n",
    "res_weights.columns=pd.MultiIndex.from_arrays(arrayres, names=('Aggregation Level', 'Indicator'))\n",
    "res_weights.drop(index=0,inplace=True)\n",
    "res_weights.index=['Weight']\n",
    "res_weights=res_weights.astype('float')\n",
    "\n",
    "wsi_weights.drop(columns='Unnamed: 0',inplace=True)\n",
    "arraywsi=[['WSI','WSI','WSI'],list(wsi_weights.iloc[0,:])]\n",
    "wsi_weights.columns=pd.MultiIndex.from_arrays(arraywsi, names=('Aggregation Level', 'Indicator'))\n",
    "wsi_weights.drop(index=0,inplace=True)\n",
    "wsi_weights.index=['Weight']\n",
    "wsi_weights=wsi_weights.astype('float')\n",
    "ahp_weights=wsi_weights.join(res_weights.join(acc_weights.join(eco_weights,how='outer'),how='outer'),how='outer')\n",
    "ahp_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_sub_columns=['ACV','MCV','Dag','Dan','GWDagr','GWDind','GWDurb','GWDrur','SWS','GWS','APA','ATA','IRWR']\n",
    "acc_sub_columns=['WAurb','WArur','USP','SAurb','SArur','TPC','WQ','DC']\n",
    "eco_sub_columns=['AE','MI','EL','NRWurb','NRWrur','IE']\n",
    "sub_columns1_list= ['R1','R1','R2','R2','R3','R3','R3','R3','R4','R4','R5','R5','R7']+['A1','A1','A1','A2','A2','A2','A3','A3']+['E1','E1','E1','E2','E2','E3']\n",
    "sub_columns2_list=res_sub_columns+acc_sub_columns+eco_sub_columns\n",
    "arraycolumns=[sub_columns1_list]+[sub_columns2_list]\n",
    "normalized_ahp=pd.DataFrame(normalized).round(decimals=4)\n",
    "normalized_ahp.columns=pd.MultiIndex.from_arrays(arraycolumns, names=('Aggregation Level', 'Indicator'))\n",
    "# normalized_ahp.to_excel('Normalized Sub Indicators 1399.xlsx')\n",
    "normalized_ahp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_lvl2=pd.DataFrame(normalized_ahp[('R4','SWS')]*0,index=sub_indicators.index)\n",
    "normalized_lvl2.columns=pd.MultiIndex.from_arrays([['R5'],['CV']], names=('Aggregation Level', 'Indicator'))\n",
    "normalized_lvl2[('R5','CV')]=weighted_addminagg(normalized_ahp.loc[:,'R1'],ahp_weights['R1']).round(decimals=4)\n",
    "normalized_lvl2[('R6','GD')]=weighted_addminagg(normalized_ahp.loc[:,'R2'],ahp_weights['R2']).round(decimals=4)\n",
    "normalized_lvl2[('R6','GWD')]=weighted_addminagg(normalized_ahp.loc[:,'R3'],ahp_weights['R3']).round(decimals=4)\n",
    "\n",
    "## Assessing water security using a mix of weighted_sum and minimum aggregation rules\n",
    "\n",
    "#  calculating indicators \n",
    "indicators_weighted=pd.DataFrame(normalized_ahp[('R4','SWS')]*0,index=sub_indicators.index)\n",
    "indicators_weighted.columns=pd.MultiIndex.from_arrays([['Resource'],['IRWR']], names=('Dimension', 'Indicator'))\n",
    "indicators_weighted[('Resource','IRWR')]=normalized_ahp.loc[:,('R7','IRWR')]\n",
    "indicators_weighted[('Resource','CC')]=weighted_addminagg(normalized_lvl2['R5'].merge(normalized_ahp['R5'], left_index=True, right_index=True,how='outer'),ahp_weights['R5']).round(decimals=4)\n",
    "indicators_weighted[('Resource','WS')]=weighted_addminagg(normalized_ahp.loc[:,'R4'],ahp_weights['R4']).round(decimals=4)\n",
    "# if a province has low groundwater reservoir deficit then high dependency on groundwater is considered okay i.e. if GD> 0.8 then GWD not involved in aggregation\n",
    "indicators_weighted.loc[normalized_lvl2[('R6','GD')]<0.8,('Resource','GW')]=weighted_addminagg(normalized_lvl2.loc[:,'R6'],ahp_weights['R6']).round(decimals=4)\n",
    "indicators_weighted.loc[normalized_lvl2[('R6','GD')]>0.8,('Resource','GW')]=normalized_lvl2.loc[:,('R6','GD')]\n",
    "indicators_weighted[('Access','DW')]=weighted_addminagg(normalized_ahp.loc[:,'A1'],ahp_weights['A1']).round(decimals=4)\n",
    "indicators_weighted[('Access','WQ')]=normalized_ahp.loc[:,('A3','WQ')]\n",
    "indicators_weighted[('Access','DC')]=normalized_ahp.loc[:,('A3','DC')]\n",
    "indicators_weighted[('Access','SS')]=weighted_addminagg(normalized_ahp.loc[:,'A2'],ahp_weights['A2']).round(decimals=4)\n",
    "indicators_weighted[('Economy','Eagr')]=weighted_addminagg(normalized_ahp.loc[:,'E1'],ahp_weights['E1']).round(decimals=4)\n",
    "indicators_weighted[('Economy','IE')]=normalized_ahp.loc[:,('E3','IE')]\n",
    "indicators_weighted[('Economy','NRW')]=weighted_addminagg(normalized_ahp.loc[:,'E2'],ahp_weights['E2']).round(decimals=4)\n",
    "\n",
    "#  calculating dimensions & WSI\n",
    "Dimensions_addminagg=pd.DataFrame(index=sub_indicators.index)\n",
    "Dimensions_addminagg['Resource']=weighted_addminagg(indicators_weighted[('Resource')],ahp_weights['R7']).round(decimals=4)\n",
    "Dimensions_addminagg['Access']=weighted_addminagg(indicators_weighted[('Access')],ahp_weights['A3']).round(decimals=4)\n",
    "Dimensions_addminagg['Economy']=weighted_addminagg(indicators_weighted[('Economy')],ahp_weights['E3']).round(decimals=4)\n",
    "Dimensions_addminagg['WSI']=weighted_addminagg(Dimensions_addminagg,ahp_weights['WSI']).round(decimals=4)\n",
    "Dimensions_addminagg.sort_values('WSI',ascending=False)\n",
    "# Dimensions_addminagg.to_excel('WSI 1399.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:643: UserWarning: merging between different levels can give an unintended result (2 levels on the left,1 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# correlation analysis\n",
    "Res_vs_subs=normalized_ahp.iloc[:,:13].join(Dimensions_addminagg['Resource'])\n",
    "Acc_vs_subs=normalized_ahp.iloc[:,13:21].join(Dimensions_addminagg['Access'])\n",
    "Eco_vs_subs=normalized_ahp.iloc[:,21:].join(Dimensions_addminagg['Economy'])\n",
    "Res_corr=Res_vs_subs.corr(method='pearson')['Resource']\n",
    "Acc_corr=Acc_vs_subs.corr(method='kendall')['Access']\n",
    "Eco_corr=Eco_vs_subs.corr(method='kendall')['Economy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer = pd.ExcelWriter('Normalized Indicators.xlsx', engine='xlsxwriter')\n",
    "# indicators_weighted.to_excel(writer,sheet_name='Indicators')\n",
    "# normalized_lvl2.to_excel(writer,sheet_name='Level 2 Sub_Indicators')\n",
    "# writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer = pd.ExcelWriter('Dimensions & WSI.xlsx', engine='xlsxwriter')\n",
    "# Dimensions_addminagg.to_excel(writer,sheet_name='Mean-Min')\n",
    "# Dimensions_weightedsum.to_excel(writer,sheet_name='Mean')\n",
    "# Dimensions_weightedgeo.to_excel(writer,sheet_name='Geo')\n",
    "# Dimensions_addgeo.to_excel(writer,sheet_name='Mean-Geo')\n",
    "# writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
